{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slibolt/ADS500B/blob/main/ADS_502_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Data & Libraries**"
      ],
      "metadata": {
        "id": "sf2rN10imnu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#library imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "A9mm1j9Fgh4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import data directly from github\n",
        "url = 'https://raw.githubusercontent.com/mitosisgg/ads502-finalproject/main/breast_cancer.csv?token=GHSAT0AAAAAACU6FR4JKKK4RMB3LVBAV752ZVMB74A' # Use raw.githubusercontent.com\n",
        "df_original = pd.read_csv(url)\n",
        "df_original.head()"
      ],
      "metadata": {
        "id": "5UBd83IQgoP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data trim, per study \"best predictive accuracy obtained using one separating plane in the 3-D space of Worst Area, Worst Smoothness and Mean Texture.\"\n",
        "df = df_original[['diagnosis', 'area_worst', 'smoothness_worst', 'texture_mean']]\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "ardtbNDEgwuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert diagnosis to binary\n",
        "df.loc[:, 'diagnosis'] = df['diagnosis'].replace({'M': 1, 'B': 0})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "EvvTKJjkg52d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Data Information**"
      ],
      "metadata": {
        "id": "41BO9Injmd3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get shape\n",
        "df.shape\n"
      ],
      "metadata": {
        "id": "Ixyvl8DoiST5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#are there duplicates?\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "V__vvGHIiXHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'] = df['diagnosis'].astype(int)"
      ],
      "metadata": {
        "id": "PLX12W6zlBmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get datatypes\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "saDFijmoiZ_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# is there class imbalance?\n",
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "PVYpRKoAg-v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='diagnosis', data=df)"
      ],
      "metadata": {
        "id": "OyulVFiIhInf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#percentage of binary class\n",
        "print(\"percentage of each class\", df['diagnosis'].value_counts()/len(df)*100)"
      ],
      "metadata": {
        "id": "ALI2JoTbhMcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Quality Report**\n",
        "\n",
        "## **Continuous Features**"
      ],
      "metadata": {
        "id": "No6K0-M0mNGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify continuous features\n",
        "conf = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "conf"
      ],
      "metadata": {
        "id": "TRLG3-tphPJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#identify any columns to filter out from the \"continuous features\"\n",
        "conf_exclude = ['']\n",
        "filter_conf = [x for x in conf if x not in conf_exclude]\n",
        "filter_conf"
      ],
      "metadata": {
        "id": "nN-uhtzShVfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get summary stats on continuous\n",
        "df[filter_conf].describe()"
      ],
      "metadata": {
        "id": "9dbnysa7hgbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_quality_conf = pd.DataFrame({\n",
        "    'Feature': filter_conf,\n",
        "    'Count': df[filter_conf].count().values,\n",
        "    'Missing Values': df[filter_conf].isnull().sum().values,\n",
        "    'Cardinality': df[filter_conf].nunique().values,\n",
        "    'Min': df[filter_conf].min().values,\n",
        "    '1st Quartile': df[filter_conf].quantile(0.25).values,\n",
        "    'Mean': df[filter_conf].mean().values,\n",
        "    'Median': df[filter_conf].median().values,\n",
        "    '3rd Quartile': df[filter_conf].quantile(0.75).values,\n",
        "    'Max': df[filter_conf].max().values,\n",
        "    'Standard Deviation': df[filter_conf].std().values,\n",
        "})\n",
        "data_quality_conf"
      ],
      "metadata": {
        "id": "cjinwC9_hpOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Univariate Analysis**"
      ],
      "metadata": {
        "id": "Bpq9Wf4hlb5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot histograms for numerical variables\n",
        "plt.style.use('ggplot')\n",
        "for column in filter_conf:\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(df[column], kde = True)\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ar1dqw14htod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot boxplots of all continuous features\n",
        "plt.style.use('ggplot')\n",
        "for column in filter_conf:\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.boxplot(x=df[column])\n",
        "    plt.title(f'Boxplot of {column}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "96wUhuQfle0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multivariate Analysis**"
      ],
      "metadata": {
        "id": "49qNQH0ulwBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#correlations, all\n",
        "corr_matrix = df[filter_conf].corr()\n",
        "corr_matrix"
      ],
      "metadata": {
        "id": "2NgS0k0yluZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a heatmap\n",
        "plt.figure(figsize=(16, 12))\n",
        "heatmap = sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5, annot_kws={\"size\": 8})\n",
        "\n",
        "# Rotate the x and y labels for better readability\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "# Show the heatmap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_G-YbA1Fl4WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df, hue =\"diagnosis\", height=3)"
      ],
      "metadata": {
        "id": "vNfGy3y7l8I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "o6Yw3LemPTFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing necessary libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "sXKZOTyirsZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing features (X) and target (y)\n",
        "X = df[['area_worst', 'smoothness_worst', 'texture_mean']]\n",
        "y = df['diagnosis']\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "JKnU4EvuPk8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Evaluation\n",
        "\n"
      ],
      "metadata": {
        "id": "-eh0o_B1QOKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize StratifiedKFold with 5 folds\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "accuracy_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "roc_aucs = []\n",
        "\n",
        "# Performing stratified k-fold cross-validation\n",
        "for train_index, test_index in skf.split(X_scaled, y):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Initializing the logistic regression model\n",
        "    model = LogisticRegression(max_iter=10000)\n",
        "\n",
        "    # Train the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "    # Append metrics to lists\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "    roc_aucs.append(roc_auc)\n",
        "\n",
        "    # Print metrics for this fold\n",
        "    print(f'Fold Accuracy: {accuracy:.4f}')\n",
        "    print(f'Fold Precision: {precision:.4f}')\n",
        "    print(f'Fold Recall: {recall:.4f}')\n",
        "    print(f'Fold F1 Score: {f1:.4f}')\n",
        "    print(f'Fold ROC AUC: {roc_auc:.4f}')\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Calculate and print mean and standard deviation of each metric\n",
        "def print_metrics_summary(name, metrics):\n",
        "    mean_metric = np.mean(metrics)\n",
        "    std_metric = np.std(metrics, ddof=1)\n",
        "    print(f'Mean {name}: {mean_metric:.4f}')\n",
        "    print(f'Standard Deviation of {name}: {std_metric:.4f}')\n",
        "\n",
        "print_metrics_summary('Accuracy', accuracy_scores)\n",
        "print_metrics_summary('Precision', precisions)\n",
        "print_metrics_summary('Recall', recalls)\n",
        "print_metrics_summary('F1 Score', f1_scores)\n",
        "print_metrics_summary('ROC AUC', roc_aucs)"
      ],
      "metadata": {
        "id": "XURQFGI8QXI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output metrics indicate that the model is performing quite well, here is summary:\n",
        "\n",
        "**Fold-wise Metrics**\n",
        "\n",
        "\n",
        "1.   Fold Accuracy:\n",
        "\n",
        "    *   Fold 1: 0.9649\n",
        "\n",
        "    *   Fold 2: 0.9474\n",
        "\n",
        "    *   Fold 3: 0.9649\n",
        "\n",
        "    *   Fold 4: 0.9825\n",
        "\n",
        "    *   Fold 5: 0.9558\n",
        "\n",
        "\n",
        "2.   Fold Precision:\n",
        "\n",
        "    *   Fold 1:  0.9535\n",
        "\n",
        "    *   Fold 2: 1.0000\n",
        "\n",
        "    *   Fold 3: 1.0000\n",
        "\n",
        "    *   Fold 4: 0.9545\n",
        "\n",
        "    *   Fold 5: 0.9744\n",
        "\n",
        "\n",
        "3.   Fold Recall:\n",
        "\n",
        "    *   Fold 1: 0.9535\n",
        "\n",
        "    *   Fold 2: 0.8605\n",
        "\n",
        "    *   Fold 3: 0.9048\n",
        "\n",
        "    *   Fold 4: 1.0000\n",
        "\n",
        "    *   Fold 5: 0.9048\n",
        "\n",
        "   \n",
        "4.   Fold F1 Score:\n",
        "\n",
        "    *   Fold 1: 0.9535\n",
        "\n",
        "    *   Fold 2: 0.9250\n",
        "\n",
        "    *   Fold 3: 0.9500\n",
        "\n",
        "    *   Fold 4: 0.9767\n",
        "\n",
        "    *   Fold 5: 0.9383\n",
        "\n",
        "\n",
        " 5.   Fold ROC AUC:\n",
        "\n",
        "    *   Fold 1: 0.9980\n",
        "\n",
        "    *   Fold 2: 0.9866\n",
        "\n",
        "    *   Fold 3: 0.9818\n",
        "\n",
        "    *   Fold 4: 1.0000\n",
        "\n",
        "    *   Fold 5: 0.9950\n",
        "\n",
        "\n",
        "**Summary Metrics**\n",
        "\n",
        "*   Mean Accuracy: 0.9631\n",
        "\n",
        "*   Standard Deviation of Accuracy: 0.0131\n",
        "\n",
        "*   Mean Precision: 0.9765\n",
        "\n",
        "*   Standard Deviation of Precision: 0.0230\n",
        "\n",
        "*   Mean Recall: 0.9247\n",
        "\n",
        "*   Standard Deviation of Recall: 0.0534\n",
        "\n",
        "*   Mean F1 Score: 0.9487\n",
        "\n",
        "*   Standard Deviation of F1 Score: 0.0192\n",
        "\n",
        "*   Mean ROC AUC: 0.9923\n",
        "\n",
        "*   Standard Deviation of ROC AUC: 0.0078\n",
        "\n",
        "\n",
        "**Accuracy:** The accuracy is consistently high across all folds, indicating that the model is performing well in distinguishing classes.\n",
        "\n",
        "\n",
        "**Precision and Recall:** High precision indicates few false positives, while recall values are slightly more variable, reflecting differences in detecting true positives across folds.\n",
        "\n",
        "**F1 Score:** This combines precision and recall, showing balanced performance.\n",
        "\n",
        "\n",
        "**ROC AUC:** High values close to 1 indicate excellent performance in distinguishing classes.\n",
        "\n",
        "**Confusion Matrices**\n",
        "\n",
        "*   Fold 1: [[69 2], [ 2 41]]\n",
        "\n",
        "*   Fold 2: [[71 0], [ 6 37]]\n",
        "\n",
        "*   Fold 3: [[72 0], [ 4 38]]\n",
        "\n",
        "*   Fold 4: [[70 2], [ 0 42]]\n",
        "\n",
        "*   Fold 5: [[70 1], [ 4 38]]\n",
        "\n",
        "\n",
        "\n",
        "**Conclusion**\n",
        "The standard deviations are relatively low, suggesting stable performance. The use of StratifiedKFold ensures that the class distribution is maintained across each fold, contributing to reliable validation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X3YNO_iZRno9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizations"
      ],
      "metadata": {
        "id": "dr6gl4m8Qjk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define color maps for visualization\n",
        "cmap_cv = plt.get_cmap('coolwarm')\n",
        "cmap_data = plt.get_cmap('tab10')\n",
        "\n",
        "# Define visualization function for cross-validation indices\n",
        "def plot_cv_indices(cv, X, y, ax, n_splits, lw=10):\n",
        "\n",
        "#Create a plot for indices of a cross-validation object\n",
        "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
        "        indices = np.array([np.nan] * len(X))\n",
        "        indices[tt] = 1  # Testing set\n",
        "        indices[tr] = 0  # Training set\n",
        "        ax.scatter(range(len(indices)), [ii + 0.5] * len(indices), c=indices, marker=\"_\", lw=lw, cmap=cmap_cv, vmin=-0.2, vmax=1.2)\n",
        "\n",
        "    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data)\n",
        "    yticklabels = list(range(n_splits)) + [\"class\"]\n",
        "    ax.set(yticks=np.arange(n_splits + 1) + 0.5, yticklabels=yticklabels, xlabel=\"Sample index\", ylabel=\"CV iteration\", ylim=[n_splits + 1.2, -0.2], xlim=[0, len(X)])\n",
        "    ax.set_title(\"Cross-Validation Splits\", fontsize=15)\n",
        "    return ax\n",
        "\n",
        "# Creating a plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plot_cv_indices(skf, X_scaled, y, ax, n_splits=5)\n",
        "plt.show()\n",
        "\n",
        "# Plotting fold distribution\n",
        "def plot_fold_distribution(cv, X, y, ax):\n",
        "    fold_sizes = [np.sum(y.iloc[tt] == 1) for _, tt in cv.split(X, y)]\n",
        "    class_0 = [np.sum(y.iloc[tt] == 0) for _, tt in cv.split(X, y)]\n",
        "    class_1 = [np.sum(y.iloc[tt] == 1) for _, tt in cv.split(X, y)]\n",
        "\n",
        "    df_fold = pd.DataFrame({'Fold': list(range(len(fold_sizes))), 'Class 0': class_0, 'Class 1': class_1})\n",
        "    df_fold.set_index('Fold').plot(kind='bar', ax=ax)\n",
        "    ax.set_xlabel('Fold')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_title('Distribution of Classes Across Folds')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "plot_fold_distribution(skf, X_scaled, y, ax)\n",
        "plt.show()\n",
        "\n",
        "# Plotting class distribution heatmap\n",
        "def plot_class_distribution_heatmap(cv, X, y, ax):\n",
        "    fold_class_distribution = []\n",
        "    for train_idx, test_idx in cv.split(X, y):\n",
        "        fold_class_distribution.append(np.bincount(y.iloc[test_idx], minlength=2))\n",
        "\n",
        "    df_class_dist = pd.DataFrame(fold_class_distribution, columns=['Class 0', 'Class 1'])\n",
        "    sns.heatmap(df_class_dist, annot=True, cmap='Blues', fmt='d', ax=ax)\n",
        "    ax.set_xlabel('Class')\n",
        "    ax.set_ylabel('Fold')\n",
        "    ax.set_title('Class Distribution Across Folds')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "plot_class_distribution_heatmap(skf, X_scaled, y, ax)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ix79gs-HQfp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-Validation Splits Plot\n",
        "\n",
        "Description:\n",
        "\n",
        "*   The first plot shows the indices of samples used for training (blue) and testing (red) across different cross-validation (CV) iterations.\n",
        "\n",
        "*   The \"class\" row at the bottom indicates the actual class distribution of the samples.\n",
        "\n",
        "Key Points:\n",
        "\n",
        "*   **Consistent Distribution:** The plot shows a consistent distribution of training and testing samples across all folds, which ensures that each fold has a representative sample of the overall dataset.\n",
        "\n",
        "*   **Class Distribution:** The \"class\" row indicates the balance of the classes in the dataset, which appears to be relatively balanced.\n",
        "\n",
        "\n",
        "Usage:\n",
        "\n",
        "*   This plot is useful for visualizing how the data is split into training and testing sets during each fold of the cross-validation process.\n",
        "\n",
        "*   It helps in ensuring that the stratification process is working correctly, preserving the class distribution in each fold.\n",
        "\n",
        "## Distribution of Classes Across Folds\n",
        "\n",
        "Description:\n",
        "\n",
        "*   The second plot is a bar chart showing the distribution of classes (Class 0 and Class 1) across different folds.\n",
        "\n",
        "*   The x-axis represents the fold number, and the y-axis represents the count of samples for each class.\n",
        "\n",
        "\n",
        "Key Points:\n",
        "\n",
        "*   **Balanced Classes:** Each fold contains a similar number of samples for Class 0 and Class 1, indicating that the stratified cross-validation is preserving the class balance.\n",
        "\n",
        "*   **Uniform Distribution:** The consistent height of the bars across folds shows that the distribution of classes is uniform across all folds.\n",
        "\n",
        "Usage:\n",
        "\n",
        "*   This plot is useful for confirming that each fold has a balanced distribution of the target classes.\n",
        "\n",
        "*   It helps in validating the effectiveness of the StratifiedKFold method in maintaining class balance.\n",
        "\n",
        "## Class Distribution Heatmap\n",
        "\n",
        "Description:\n",
        "\n",
        "*   The third plot is a heatmap showing the distribution of classes across different folds.\n",
        "\n",
        "*   The x-axis represents the classes (Class 0 and Class 1), and the y-axis represents the fold number.\n",
        "\n",
        "\n",
        "Key Points:\n",
        "\n",
        "*  **Counts per Class:** The heatmap values indicate the count of each class in each fold.\n",
        "\n",
        "*   **Color Intensity:** The color intensity represents the number of samples, with darker colors indicating higher counts.\n",
        "\n",
        "Usage:\n",
        "\n",
        "*   This plot provides a visual representation of the class distribution across folds.\n",
        "\n",
        "*   It is useful for quickly identifying any discrepancies in the distribution of classes in different folds.\n",
        "\n",
        "**Summary**\n",
        "\n",
        "**Cross-Validation Splits Plot:** Ensures proper stratification and visualizes the data splitting process.\n",
        "\n",
        "**Distribution of Classes Across Folds:** Confirms the uniform distribution of classes across folds, validating the effectiveness of stratified cross-validation.\n",
        "\n",
        "**Class Distribution Heatmap:** Provides a detailed view of class counts in each fold, highlighting the balance maintained across folds.\n",
        "\n"
      ],
      "metadata": {
        "id": "4msT24SYXAnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC Curve Plotting"
      ],
      "metadata": {
        "id": "xB-XihE_Q2qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curve for each fold\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "mean_tpr = np.zeros_like(mean_fpr)\n",
        "\n",
        "for train_index, test_index in skf.split(X_scaled, y):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=1, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "\n",
        "mean_tpr /= skf.get_n_splits()\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "\n",
        "# Plot settings\n",
        "plt.plot(mean_fpr, mean_tpr, color='b', lw=2, label=f'Mean ROC curve (area = {mean_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RgoyiigbQzty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roc curve  plots the True Positive Rate (TPR) against the False Positive Rate (FPR).\n",
        "\n",
        "**Mean ROC Curve:**\n",
        "\n",
        "*   The mean ROC curve, plotted in blue, represents the average performance across all folds.\n",
        "\n",
        "*   It has an AUC of 0.99, indicating excellent overall performance.\n",
        "\n",
        "**Diagonal Line:** The dashed diagonal line represents the ROC curve of a random classifier with an AUC of 0.50. This serves as a baseline for comparison.\n",
        "\n",
        "**AUC**: The AUC values for the individual folds are very high (ranging from 0.98 to 1.00), indicating that the model performs exceptionally well in distinguishing between the positive and negative classes.\n",
        "\n",
        "The ROC curves for different folds are very close to each other, demonstrating consistent performance across the cross-validation folds. This suggests that the model's performance is stable and not heavily influenced by the particular train-test split.\n",
        "\n",
        "The curves show a sharp increase in the True Positive Rate (TPR) with a very small increase in the False Positive Rate (FPR), indicating that the model has a high sensitivity (recall) and specificity.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u7ZLKxgKD7XA"
      }
    }
  ]
}